{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso di Pipeline di Machine Learning in Spark\n",
    "\n",
    "Parteciperemo \"virtualmente\" alla competizione sul Titanic data set organizzata sul portale [Kaggle](https://www.kaggle.com/c/titanic/overview) da cui trarremo i due data set di addestramento e test. Nel resto dell'esempio i dati si troveranno all'interno del file system Hadoop.\n",
    "\n",
    "Il training set consta di 891 righe e il test set di 418 e non ha la colonna dei sopravvissuti. Addestreremo un classificatore Random Forests su una griglia di iperparametri valutati con una procedura di 10-fold crossvalidation.\n",
    "\n",
    "Dapprima ci preoccuperemo di gestire le feature mancanti e, successivamente, costruiremo la Pipeline Spark di addestramento e valutazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inizializziamo la SparkSession e importiamo le librerie\n",
    "import findspark\n",
    "\n",
    "location = findspark.find()\n",
    "findspark.init(location)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.ml.classification import RandomForestClassifier \n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark ML example on titanic data \") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carichiamo il data set\n",
    "\n",
    "trainDF = spark \\\n",
    "    .read \\\n",
    "    .csv('hdfs://localhost:9099/user/pirrone/spark/ml/input/train.csv',header = 'True', inferSchema='True')\n",
    "\n",
    "testDF = spark \\\n",
    "    .read \\\n",
    "    .csv('hdfs://localhost:9099/user/pirrone/spark/ml/input/test.csv',header = 'True', inferSchema='True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostriamo un il data set po' di informazioni sulle feature\n",
    "\n",
    "display(trainDF)\n",
    "display(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "test set\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostriamo lo schema\n",
    "print(\"training set\")\n",
    "trainDF.printSchema()\n",
    "\n",
    "print(\"\\n\\ntest set\")\n",
    "testDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passeggeri: 891\n",
      "Di cui sopravvissuti: 342\n",
      "+-------+-----------------+------------------+--------+-----+\n",
      "|summary|             Fare|               Age|Embarked|Cabin|\n",
      "+-------+-----------------+------------------+--------+-----+\n",
      "|  count|              891|               714|     889|  204|\n",
      "|   mean| 32.2042079685746| 29.69911764705882|    null| null|\n",
      "| stddev|49.69342859718089|14.526497332334035|    null| null|\n",
      "|    min|              0.0|              0.42|       C|  A10|\n",
      "|    max|         512.3292|              80.0|       S|    T|\n",
      "+-------+-----------------+------------------+--------+-----+\n",
      "\n",
      "Passeggeri: 418\n",
      "+-------+------------------+------------------+--------+-----+\n",
      "|summary|              Fare|               Age|Embarked|Cabin|\n",
      "+-------+------------------+------------------+--------+-----+\n",
      "|  count|               417|               332|     418|   91|\n",
      "|   mean|  35.6271884892086|30.272590361445783|    null| null|\n",
      "| stddev|55.907576179973844|14.181209235624424|    null| null|\n",
      "|    min|               0.0|              0.17|       C|  A11|\n",
      "|    max|          512.3292|              76.0|       S|   G6|\n",
      "+-------+------------------+------------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contiamo imbarcati e sopravvissuti e verifichiamo se ci sono valori mancanti\n",
    "# nelle righe\n",
    "\n",
    "passengers_count = trainDF.count()\n",
    "survived_count = trainDF.filter(\"Survived == 1\").count()\n",
    "\n",
    "print(f\"Passeggeri: {passengers_count}\\nDi cui sopravvissuti: {survived_count}\")\n",
    "\n",
    "trainDF.describe()['summary','Fare','Age','Embarked','Cabin'].show()\n",
    "\n",
    "print(f\"Passeggeri: {testDF.count()}\")\n",
    "testDF.describe()['summary','Fare','Age','Embarked','Cabin'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|                   Age|              177|\n",
      "|                 Cabin|              687|\n",
      "|              Embarked|                2|\n",
      "+----------------------+-----------------+\n",
      "\n",
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|                   Age|               86|\n",
      "|                  Fare|                1|\n",
      "|                 Cabin|              327|\n",
      "+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# contiamo i valori nulli nelle diverse colonne tramite una UDF\n",
    "\n",
    "def null_value_count(df):\n",
    "  null_columns_counts = []\n",
    "  for k in df.columns:\n",
    "    nullRows = df.where(col(k).isNull()).count()\n",
    "    if(nullRows > 0):\n",
    "      temp = k,nullRows\n",
    "      null_columns_counts.append(temp)\n",
    "  return(null_columns_counts)\n",
    "\n",
    "null_columns_count_list_train = null_value_count(trainDF)\n",
    "null_columns_count_list_test = null_value_count(testDF)\n",
    "\n",
    "spark.createDataFrame(null_columns_count_list_train, ['Column_With_Null_Value', 'Null_Values_Count']).show()\n",
    "\n",
    "spark.createDataFrame(null_columns_count_list_test, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|     Initial|\n",
      "+------------+\n",
      "|         Don|\n",
      "|        Miss|\n",
      "|         Col|\n",
      "|         Rev|\n",
      "|        Lady|\n",
      "|      Master|\n",
      "|         Mme|\n",
      "|        Capt|\n",
      "|          Mr|\n",
      "|          Dr|\n",
      "|         Mrs|\n",
      "|         Sir|\n",
      "|    Jonkheer|\n",
      "|        Mlle|\n",
      "|       Major|\n",
      "|          Ms|\n",
      "|the Countess|\n",
      "+------------+\n",
      "\n",
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|   Dona|\n",
      "|   Miss|\n",
      "|    Col|\n",
      "|    Rev|\n",
      "| Master|\n",
      "|     Mr|\n",
      "|     Dr|\n",
      "|    Mrs|\n",
      "|     Ms|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gestione dei valori nulli:\n",
    "\n",
    "-- Age: calcoleremo l'età media dei paseggeri raggruppati per 'titolo' nel nome (Mr, Mrs, Miss, ...) poiché questo corrisponde a delle precise fasce di età\n",
    "-- Fare (solo test): calcoleremo il valor medio della tariffa\n",
    "-- Cabin: faremo il drop della feature perché non interessa\n",
    "-- Embarked: non è molto rilevante ai fini della classificazione, ma faremo imputazione con il valore più frequente e cioé 'S'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# estraiamo la lista dei titoli su entrambi i dataframe\n",
    "trainDF=trainDF.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\".*, (.*?)\\\\..*\",1))\n",
    "testDF=testDF.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\".*, (.*?)\\\\..*\",1))\n",
    "\n",
    "trainDF.select(\"Initial\").distinct().show()\n",
    "testDF.select(\"Initial\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Oliva y Ocana, Dona. Fermina')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.select(testDF.Name).where(testDF.Initial=='Dona').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|    Don|\n",
      "|   Miss|\n",
      "|    Col|\n",
      "|    Rev|\n",
      "| Master|\n",
      "|     Mr|\n",
      "|     Dr|\n",
      "|    Mrs|\n",
      "|    Sir|\n",
      "+-------+\n",
      "\n",
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|   Miss|\n",
      "|    Col|\n",
      "|    Rev|\n",
      "| Master|\n",
      "|     Mr|\n",
      "|     Dr|\n",
      "|    Mrs|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I titoli sono molto vari e, dall'analisi diretta del dataframe, emerge la necessità di mapparne alcuni in un set standard\n",
    "\n",
    "trainDF = trainDF.replace(\\\n",
    "    ['Mlle','Mme', 'Ms', 'Major','Lady','the Countess','Jonkheer','Capt'],\\\n",
    "    ['Miss','Miss','Miss','Col',  'Mrs',  'Mrs',  'Sir',  'Col',])\n",
    "\n",
    "trainDF.select(\"Initial\").distinct().show()\n",
    "\n",
    "testDF = testDF.replace(['Dona','Ms'],['Mrs','Miss'])\n",
    "\n",
    "testDF.select(\"Initial\").distinct().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+--------+\n",
      "|Initial| Age|   Fare|Embarked|\n",
      "+-------+----+-------+--------+\n",
      "|     Mr|22.0|   7.25|       S|\n",
      "|    Mrs|38.0|71.2833|       C|\n",
      "|   Miss|26.0|  7.925|       S|\n",
      "|    Mrs|35.0|   53.1|       S|\n",
      "|     Mr|35.0|   8.05|       S|\n",
      "|     Mr|null| 8.4583|       Q|\n",
      "|     Mr|54.0|51.8625|       S|\n",
      "| Master| 2.0| 21.075|       S|\n",
      "|    Mrs|27.0|11.1333|       S|\n",
      "|    Mrs|14.0|30.0708|       C|\n",
      "|   Miss| 4.0|   16.7|       S|\n",
      "|   Miss|58.0|  26.55|       S|\n",
      "|     Mr|20.0|   8.05|       S|\n",
      "|     Mr|39.0| 31.275|       S|\n",
      "|   Miss|14.0| 7.8542|       S|\n",
      "|    Mrs|55.0|   16.0|       S|\n",
      "| Master| 2.0| 29.125|       Q|\n",
      "|     Mr|null|   13.0|       S|\n",
      "|    Mrs|31.0|   18.0|       S|\n",
      "|    Mrs|null|  7.225|       C|\n",
      "+-------+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calcoliamo l'età media per i vari gruppi di titoli e imputiamo i valori nulli di età\n",
    "from math import floor\n",
    "\n",
    "# creiamo un unico dataframe per gestire i valori medi di 'Age' e 'Fare' nonché il valore maggiormente \n",
    "# occorrente di 'Embarked'\n",
    "\n",
    "pivotDF = trainDF['Initial','Age','Fare','Embarked'].unionByName(testDF['Initial','Age','Fare','Embarked'])\n",
    "\n",
    "pivotDF.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_age_lis=pivotDF.groupby('Initial').avg('Age').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.29547928134553"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for row in avg_age_list:\n",
    "    trainDF=trainDF.withColumn(\"Age\",when((trainDF[\"Initial\"]==row[0]) & \\\n",
    "        (trainDF[\"Age\"].isNull()),floor(row[1]+0.5)).otherwise(trainDF[\"Age\"]))\n",
    "    testDF=testDF.withColumn(\"Age\",when((testDF[\"Initial\"]==row[0]) & \\\n",
    "        (testDF[\"Age\"].isNull()),floor(row[1]+0.5)).otherwise(testDF[\"Age\"]))\n",
    "\n",
    "avg_fare = pivotDF.select(avg(pivotDF.Fare)).collect()[0][0]\n",
    "\n",
    "avg_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string, Initial: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.withColumn(\"Fare\",when(testDF[\"Fare\"].isNull(),avg_fare).otherwise(testDF[\"Fare\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|  123|\n",
      "|    null|    2|\n",
      "|       C|  270|\n",
      "|       S|  914|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Completiamo l'imputazione Verificando il luogo di imbarco della maggior parte dei passeggeri\n",
    "\n",
    "pivotDF.groupBy(\"Embarked\").count().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputiamo il valore 'S' per il campo 'Embarked'\n",
    "\n",
    "trainDF = trainDF.na.fill({\"Embarked\" : 'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|FamilySize|count|\n",
      "+----------+-----+\n",
      "|         1|  537|\n",
      "|         6|   22|\n",
      "|         3|  102|\n",
      "|         5|   15|\n",
      "|         4|   29|\n",
      "|         8|    6|\n",
      "|         7|   12|\n",
      "|        11|    7|\n",
      "|         2|  161|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|FamilySize|count|\n",
      "+----------+-----+\n",
      "|         1|  253|\n",
      "|         6|    3|\n",
      "|         3|   57|\n",
      "|         5|    7|\n",
      "|         4|   14|\n",
      "|         8|    2|\n",
      "|         7|    4|\n",
      "|        11|    4|\n",
      "|         2|   74|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creiamo una colonna \"FamilySize\" che somma \"Parch\" (Parents/children) e \"Sibsp\" (Sibling/spouses) + 1\n",
    "\n",
    "trainDF = trainDF.withColumn(\"FamilySize\",col('SibSp')+col('Parch')+1)\n",
    "testDF = testDF.withColumn(\"FamilySize\",col('SibSp')+col('Parch')+1)\n",
    "\n",
    "trainDF.groupBy(\"FamilySize\").count().show()\n",
    "testDF.groupBy(\"FamilySize\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo anche una colonna binaria \"Alone\" per indicar coloro che viaggiano soli (\"FamilySize = 1\")\n",
    "\n",
    "trainDF = trainDF.withColumn('Alone',lit(0))\n",
    "trainDF = trainDF.withColumn(\"Alone\",when(trainDF[\"FamilySize\"] == 1, 1).otherwise(trainDF[\"Alone\"]))\n",
    "\n",
    "testDF = testDF.withColumn('Alone',lit(0))\n",
    "testDF = testDF.withColumn(\"Alone\",when(testDF[\"FamilySize\"] == 1, 1).otherwise(testDF[\"Alone\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cominciamo a creare la pipeline di addestramento e test\n",
    "# Una pipeline è una sequenza ordinata di:\n",
    "#\n",
    "# Transformers: algoritmi che trasformano effettivamente un dataframe (metodo transform())\n",
    "# Estimators: algoritmi che si addestrano sui dati per generare un Transformer (metodo fit() che usa \n",
    "#   la \"eager execution\" ovvero l'esecuzione immediata)\n",
    "# Evaluators: algoritmi di calcolo dei criteri di valutazione delle performance\n",
    "#\n",
    "# Ad es. un algoritmo di machine learning è un Estimator che, opportunamente parametrizzato e \n",
    "# addestrato, genera un Transformer cioè il modello che trasforma feature in predizioni\n",
    "#\n",
    "# Sono Transformer anche gli algoritmi di gestione delle feature in ingresso e uscita\n",
    "#\n",
    "# La Pipeline può contenere anche algoritmi per il tuning degli iperparametri\n",
    "\n",
    "# Eseguiremo il fit degli Estimators (incluso quindi l'addestramento vero e proprio) sul trainDF\n",
    "# Eseguiremo il transform del modello addestrato (che è un Transformer) e la valutazione sul testDF\n",
    "\n",
    "# Indicizziamo i dati categorici (tranne \"Survived\") su un unico dataframe contenente training e test \n",
    "# set. Questa soluzione si giustifica con il fatto che lo StringIndexer crea degli indici numerici con \n",
    "# le frequenze di occorrenza delle etichette catgoriche, quindi è più opportuno farne il \"fit\" su \n",
    "# tutti i dati\n",
    "\n",
    "labelDF = trainDF[\"Pclass\",\"Sex\",\"Embarked\",\"Initial\",\"Alone\"].\\\n",
    "          unionByName(testDF[\"Pclass\",\"Sex\",\"Embarked\",\"Initial\",\"Alone\"])\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(labelDF) for column in [\"Pclass\",\"Sex\",\"Embarked\",\"Initial\",\"Alone\"]]\n",
    "\n",
    "# Trasformiamo il data set per ottenere realmente le colonne indicizzate e utilizzarle poi come feature\n",
    "for indexer in indexers:\n",
    "    trainDF=indexer.transform(trainDF)\n",
    "    testDF=indexer.transform(testDF)\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol='Survived',outputCol='Survived_index').fit(trainDF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un mapping per le label predette dall'algoritmo che, dopo l'addestramento, restituirà una \n",
    "# colonna \"prediction\" indicizzata\n",
    "\n",
    "labelConverter = IndexToString(inputCol='prediction',outputCol='predictedLabel').setLabels(labelIndexer.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembliamo le feature con un VectorAssembler cioè un Transformer che crea il vettore di tutte le \n",
    "# feature concatenate\n",
    "\n",
    "assembler = VectorAssembler().setInputCols([\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"FamilySize\", \"Pclass_index\",\"Sex_index\",\"Embarked_index\",\"Initial_index\",\"Alone_index\"]).setOutputCol(\"Features\").setHandleInvalid(\"keep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il classificatore come Evaluator impostando le colonne delle feature e delle label\n",
    "# Il \"fit\" di questo Evaluator restituisce un Transformer di tipo RandomForestClassificationModel\n",
    "# il cui metodo \"transform\" possiamo usare per predire i sopravvissuti sul testDF\n",
    "\n",
    "randomForest = RandomForestClassifier().setFeaturesCol(\"Features\").setLabelCol(\"Survived_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo la pipeline per una singola classificazione\n",
    "# La pipeline, nel suo complesso, è un Evaluator il cui metodo \"fit\" genererà un Transformer per il \n",
    "# test set\n",
    "\n",
    "pipeline = Pipeline().setStages([\\\n",
    "                                labelIndexer,\\\n",
    "                                assembler,\\\n",
    "                                randomForest,\\\n",
    "                                labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costruiamo l'algoritmo di addestramento, come una 10-fold Cross-validation che si addestra su una \n",
    "# griglia di iperparametri:\n",
    "# -- l'indice di Gini, e l'entropia per controlla la purezza dei nodi foglia\n",
    "# -- il numero di bin cioè di categorie da generare per ogni feature categorica\n",
    "# -- la profondità massima dell'albero\n",
    "\n",
    "# Generiamo la griglia\n",
    "paramGrid = ParamGridBuilder().addGrid(randomForest.maxBins,[25, 28, 31])\\\n",
    "                              .addGrid(randomForest.maxDepth,[4,6,8])\\\n",
    "                              .addGrid(randomForest.impurity,[\"entropy\",\"gini\"])\\\n",
    "                              .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generiamo l'evaluator che inseriremo nell'algoritmo di addestramento. Questo utilizzerà la metrica \n",
    "# Area Under Precision-Recall curve che si adattameglio ad una classificazione binaria con classi \n",
    "# sbilanciate, com'è il nostro caso in cui i sopravvissuti sono pochi\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator().setLabelCol(\"Survived_index\")\\\n",
    "                                           .setMetricName(\"areaUnderPR\")\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infine costruiamo l'Estimator che implementa la 10-fold cross-validation, inserendo la pipeline come \n",
    "# Estimator dei dati, l'evaluator e la griglia degli iperparametri per l'addestramento\n",
    "\n",
    "cv = CrossValidator().setEstimator(pipeline)\\\n",
    "                     .setEvaluator(evaluator)\\\n",
    "                     .setEstimatorParamMaps(paramGrid)\\\n",
    "                     .setNumFolds(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addesrtiamo sul training set\n",
    "cvModel = cv.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facciamo la predizione sul test set\n",
    "\n",
    "predictions = cvModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 93.29%\n"
     ]
    }
   ],
   "source": [
    "# Analizziamo l'accuratezza sul training set\n",
    "\n",
    "performance = cvModel.transform(trainDF)\n",
    "auprc = evaluator.evaluate(performance)\n",
    "print(f\"Area Under PR Curve: {(100*auprc):05.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il file dei risultati per sottometterlo sul sito della competizione\n",
    "\n",
    "# Salviamo il modello addestrato\n",
    "\n",
    "cvModel.write().overwrite().save('hdfs://localhost:9099/user/pirrone/spark/ml/output/RF_10xfold_cv_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salviamo in csv con le colonne \"PassengerId\" \"Survived\"\n",
    "\n",
    "predictions\\\n",
    "  .withColumn(\"Survived\", col(\"predictedLabel\"))\\\n",
    "  .select(\"PassengerId\", \"Survived\")\\\n",
    "  .coalesce(1)\\\n",
    "  .write\\\n",
    "  .csv('hdfs://localhost:9099/user/pirrone/spark/ml/output/titanic_predictions.csv',\\\n",
    "    header=True, mode='overwrite')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 ('bigdata_py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7fdaf848b1569d220adb27db25f0581f160458c042f09ff1ba22ef71dc5af32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
