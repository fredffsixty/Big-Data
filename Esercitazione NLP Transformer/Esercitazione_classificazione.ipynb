{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset https://www.kaggle.com/datasets/sainijagjit/bbc-dataset?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/home/isiragusa/irene/NLP General/Esercitazione/'\n",
    "df = pd.read_csv(PATH+\"bbc-text.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['category']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'business':0,\n",
    "          'entertainment':1,\n",
    "          'sport':2,\n",
    "          'tech':3,\n",
    "          'politics':4\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780 222 223\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 890/890 [01:58<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.756 | Train Accuracy:  0.347 | Val Loss:  0.639 | Val Accuracy:  0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [01:54<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.543 | Train Accuracy:  0.626 | Val Loss:  0.441 | Val Accuracy:  0.734\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.785\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 (default, Jul 27 2021, 14:32:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "061448e7adbb17b76f973e82ffc9480264f4afb56d4e5f7841a3e51b709e605b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
